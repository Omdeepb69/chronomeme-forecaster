{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "from prophet import Prophet\n",
        "from prophet.diagnostics import cross_validation, performance_metrics\n",
        "from prophet.plot import plot_cross_validation_metric\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "except nltk.downloader.DownloadError:\n",
        "    print('Downloading VADER lexicon...')\n",
        "    nltk.download('vader_lexicon')\n",
        "except LookupError:\n",
        "    print('Downloading VADER lexicon...')\n",
        "    nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_mock_meme_data(days=730, peak_day=365, max_mentions=10000, noise_level=0.1):\n",
        "    \"\"\"Generates mock time-series data for meme mentions and sentiment.\"\"\"\n",
        "    dates = pd.to_datetime(pd.date_range(end=datetime.date.today(), periods=days, freq='D'))\n",
        "    \n",
        "    # Simulate mention counts (logistic growth + decay)\n",
        "    x = np.arange(days)\n",
        "    # Growth phase (sigmoid)\n",
        "    growth_rate = 0.05\n",
        "    growth = max_mentions / (1 + np.exp(-growth_rate * (x - peak_day * 0.7)))\n",
        "    # Decay phase (exponential)\n",
        "    decay_rate = 0.015\n",
        "    decay_start_value = max_mentions / (1 + np.exp(-growth_rate * (peak_day - peak_day * 0.7)))\n",
        "    decay = decay_start_value * np.exp(-decay_rate * (x - peak_day))\n",
        "    \n",
        "    mentions = np.where(x < peak_day, growth, decay)\n",
        "    \n",
        "    # Add noise\n",
        "    noise = np.random.normal(0, mentions * noise_level, days)\n",
        "    mentions = np.maximum(0, mentions + noise).astype(int)\n",
        "    \n",
        "    # Simulate simple text snippets\n",
        "    texts = []\n",
        "    positive_keywords = ['lol', 'haha', 'awesome', 'love', 'funny', 'good', 'great']\n",
        "    negative_keywords = ['hate', 'stupid', 'annoying', 'bad', 'overused', 'cringe']\n",
        "    neutral_keywords = ['meme', 'post', 'share', 'see', 'trend', 'mention']\n",
        "    \n",
        "    for i in range(days):\n",
        "        # Sentiment roughly correlates with trend phase\n",
        "        if i < peak_day * 0.5: # Early growth\n",
        "            sentiment_prob = 0.6 # Mostly positive\n",
        "        elif i < peak_day * 1.2: # Peak and early decay\n",
        "            sentiment_prob = 0.4 # Mixed\n",
        "        else: # Late decay\n",
        "            sentiment_prob = 0.2 # More negative/neutral\n",
        "            \n",
        "        if np.random.rand() < sentiment_prob:\n",
        "            kw = np.random.choice(positive_keywords)\n",
        "        elif np.random.rand() < 0.7: # Higher chance of negative than neutral in later stages\n",
        "             kw = np.random.choice(negative_keywords)\n",
        "        else:\n",
        "             kw = np.random.choice(neutral_keywords)\n",
        "        texts.append(f\"Saw the {kw} meme today.\")\n",
        "        \n",
        "    df = pd.DataFrame({'date': dates, 'mentions': mentions, 'text': texts})\n",
        "    return df\n",
        "\n",
        "def load_meme_data(source='generate', **kwargs):\n",
        "    \"\"\"Simulates loading data from a project module.\"\"\"\n",
        "    print(f\"Loading data using source: {source}\")\n",
        "    if source == 'generate':\n",
        "        return generate_mock_meme_data(**kwargs)\n",
        "    # Add other potential sources like loading from CSV\n",
        "    # elif source == 'csv':\n",
        "    #     return pd.read_csv(kwargs.get('filepath'))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported data source\")\n",
        "\n",
        "# Load data\n",
        "raw_data = load_meme_data(days=730, peak_day=400, max_mentions=15000, noise_level=0.15)\n",
        "print(raw_data.head())\n",
        "print(f\"\\nData shape: {raw_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Apply sentiment analysis\n",
        "raw_data['sentiment_compound'] = raw_data['text'].apply(lambda text: analyzer.polarity_scores(text)['compound'])\n",
        "\n",
        "# Aggregate sentiment per day (if multiple entries per day existed)\n",
        "# In this mock data, we have one entry per day, so sentiment is already daily\n",
        "daily_sentiment = raw_data.set_index('date')['sentiment_compound']\n",
        "\n",
        "print(\"Sentiment analysis complete.\")\n",
        "print(raw_data[['date', 'sentiment_compound']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Prophet: requires 'ds' (datestamp) and 'y' (numeric value to forecast)\n",
        "# We will forecast 'mentions'\n",
        "df_prophet = raw_data[['date', 'mentions']].copy()\n",
        "df_prophet.rename(columns={'date': 'ds', 'mentions': 'y'}, inplace=True)\n",
        "\n",
        "# Optional: Add sentiment as a regressor\n",
        "# df_prophet['sentiment'] = raw_data['sentiment_compound'].values\n",
        "\n",
        "print(\"Data prepared for Prophet:\")\n",
        "print(df_prophet.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the model\n",
        "# We can customize seasonality and add regressors here if needed\n",
        "model = Prophet(\n",
        "    yearly_seasonality=True, \n",
        "    weekly_seasonality=True, \n",
        "    daily_seasonality=False, # Data is daily, so daily seasonality is not applicable\n",
        "    # seasonality_mode='multiplicative', # Consider if trends are multiplicative\n",
        "    # growth='logistic', # If there's a known carrying capacity\n",
        ")\n",
        "\n",
        "# Add sentiment as a regressor (if included in df_prophet)\n",
        "# model.add_regressor('sentiment')\n",
        "\n",
        "# Fit the model to the historical data\n",
        "print(\"Training Prophet model...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# If using logistic growth, define cap and floor\n",
        "# df_prophet['cap'] = df_prophet['y'].max() * 1.5 # Example capacity\n",
        "# df_prophet['floor'] = 0 # Minimum mentions\n",
        "\n",
        "model.fit(df_prophet)\n",
        "end_time = time.time()\n",
        "print(f\"Model training completed in {end_time - start_time:.2f} seconds.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a dataframe for future predictions\n",
        "future_periods = 90 # Forecast for the next 90 days\n",
        "future = model.make_future_dataframe(periods=future_periods)\n",
        "\n",
        "# Add future values for regressors if used\n",
        "# Need to forecast sentiment or assume a value\n",
        "# For simplicity, let's assume average sentiment continues\n",
        "# future_sentiment = df_prophet['sentiment'].mean()\n",
        "# future['sentiment'] = future_sentiment\n",
        "\n",
        "# If using logistic growth, add cap and floor to future dataframe\n",
        "# future['cap'] = df_prophet['cap'].iloc[0]\n",
        "# future['floor'] = df_prophet['floor'].iloc[0]\n",
        "\n",
        "print(f\"Future dataframe created for {future_periods} days:\")\n",
        "print(future.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "print(\"Generating forecast...\")\n",
        "forecast = model.predict(future)\n",
        "print(\"Forecast complete.\")\n",
        "\n",
        "# Display forecast details for the last few days\n",
        "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the forecast\n",
        "fig1 = model.plot(forecast)\n",
        "plt.title('Meme Mention Frequency Forecast')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Mentions')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot forecast components (trend, weekly/yearly seasonality)\n",
        "fig2 = model.plot_components(forecast)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Evaluation using Cross-Validation\n",
        "# 'initial': The size of the initial training period.\n",
        "# 'period': The spacing between cutoff dates.\n",
        "# 'horizon': The forecast horizon.\n",
        "print(\"Performing cross-validation...\")\n",
        "start_time_cv = time.time()\n",
        "# Use parameters appropriate for the dataset size (e.g., 1 year initial, 180 days period, 90 days horizon)\n",
        "initial_cv = f'{min(365, int(len(df_prophet)*0.5))} days'\n",
        "period_cv = f'{min(180, int(len(df_prophet)*0.2))} days'\n",
        "horizon_cv = f'{future_periods} days'\n",
        "\n",
        "df_cv = cross_validation(model, initial=initial_cv, period=period_cv, horizon=horizon_cv, parallel=\"processes\")\n",
        "end_time_cv = time.time()\n",
        "print(f\"Cross-validation completed in {end_time_cv - start_time_cv:.2f} seconds.\")\n",
        "print(df_cv.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate performance metrics\n",
        "df_p = performance_metrics(df_cv)\n",
        "print(\"Performance Metrics (MAPE, MAE, RMSE, etc.):\")\n",
        "print(df_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize cross-validation results (e.g., MAPE)\n",
        "fig_cv = plot_cross_validation_metric(df_cv, metric='mape')\n",
        "plt.title('Cross-Validation MAPE')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate 'Peak Virality' Prediction Window\n",
        "# Find the peak forecasted value in the future period\n",
        "future_forecast = forecast[forecast['ds'] > df_prophet['ds'].max()].copy()\n",
        "\n",
        "if not future_forecast.empty:\n",
        "    peak_yhat = future_forecast['yhat'].max()\n",
        "    peak_date = future_forecast.loc[future_forecast['yhat'].idxmax(), 'ds']\n",
        "    \n",
        "    print(f\"\\nPredicted peak mentions (yhat): {peak_yhat:.2f}\")\n",
        "    print(f\"Predicted peak date: {peak_date.strftime('%Y-%m-%d')}\")\n",
        "    \n",
        "    # Define a window around the peak (e.g., days where forecast is > 85% of peak)\n",
        "    peak_threshold = peak_yhat * 0.85\n",
        "    peak_window_df = future_forecast[future_forecast['yhat'] >= peak_threshold]\n",
        "    \n",
        "    if not peak_window_df.empty:\n",
        "        peak_start_date = peak_window_df['ds'].min()\n",
        "        peak_end_date = peak_window_df['ds'].max()\n",
        "        print(f\"Predicted 'Peak Virality' Window (yhat >= {peak_threshold:.2f}):\")\n",
        "        print(f\"Start: {peak_start_date.strftime('%Y-%m-%d')}\")\n",
        "        print(f\"End:   {peak_end_date.strftime('%Y-%m-%d')}\")\n",
        "        \n",
        "        # Visualize the peak window\n",
        "        fig_peak, ax_peak = plt.subplots()\n",
        "        model.plot(forecast, ax=ax_peak)\n",
        "        ax_peak.axvspan(peak_start_date, peak_end_date, color='red', alpha=0.2, label='Peak Virality Window')\n",
        "        ax_peak.plot(peak_date, peak_yhat, 'ro', markersize=8, label=f'Predicted Peak ({peak_date.strftime(\"%Y-%m-%d\")})')\n",
        "        plt.title('Meme Mention Forecast with Peak Virality Window')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Mentions')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Could not determine a peak virality window based on the threshold.\")\n",
        "else:\n",
        "    print(\"\\nNo future forecast data available to determine peak virality.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}